\documentclass[a4paper,12pt]{article}

\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{graphicx}
\usepackage{geometry}
\usepackage{subcaption}
\usepackage{setspace}
\usepackage{minted}
\usepackage{authblk}
\usepackage{caption}
\usepackage{hyperref}
\usepackage{tikz}
\usetikzlibrary{trees}
\usetikzlibrary{positioning}
\usepackage{xcolor}
\usepackage{pgfkeys}
\usepackage{booktabs}
\usepackage{listings}
\usepackage[linesnumbered,ruled,vlined]{algorithm2e}
\usepackage[noend]{algpseudocode}
\usepackage{fancyhdr}
\setlength{\parindent}{0pt}
\geometry{a4paper, margin=2.5cm}

\sloppy
\begin{document}

\begin{titlepage}

    \vspace*{4cm}

    \centering
    
    \includegraphics[width=0.6\textwidth]{Images/logo.png} \\[1.5cm]
    
    \rule{\linewidth}{1pt} \\[1cm]

    {\Huge \bfseries HAX907X Apprentissage statistique}\\[0.5cm]
    {\Huge TP : Support Vector Machines (SVM)}\\[1cm]
    
    \rule{\linewidth}{1pt} \\[2cm]

    {\Large \textbf{Marine GERMAIN}}\\
    {\Large \textbf{Coralie ROMANI DE VINCI}}\\[1cm]
    

\end{titlepage}


\renewcommand{\contentsname}{Table des matières}
\tableofcontents


\newpage

\section{Introduction}

Les \emph{Support Vector Machines} (SVM) sont une méthode de classification supervisée qui vise à séparer différentes classes en maximisant la marge entre elles. Le principe repose sur la recherche d’hyperplans séparateurs, ce qui les rend particulièrement efficaces dans des espaces de grande dimension.\\

Dans ce TP, nous mettons en pratique les SVM à l’aide du package scikit-learn. Nous appliquerons ces méthodes à la fois sur des données simulées et sur des jeux de données réels, en particulier le dataset \texttt{iris} et une base de données d'images. 
Nous analyserons également l’influence des noyaux et des hyperparamètres sur la performance des modèles, afin de mieux comprendre cette approche de classification.

\section{Base de données \texttt{iris}}

Cette section est consacrée à l'étude de la base de données \texttt{iris} sur laquelle nous ferons une étude de classification sur les classes $1$ et $2$.
Nous considérerons d'abord le noyau linéaire puis le noyau polynomial et nous les comparerons.
Le dataset est divisé en deux parties : un ensemble d'entraînement (75\% des données) et un ensemble de test (25\%). 

\subsection{Classification avec noyau linéaire}

La classification des deux premières variables avec un noyau linéaire a pour objectif de trouver un hyperplan qui sépare au mieux les deux classes en maximisant la marge entre les points des deux classes. 
Les scores obtenus pour cette méthode sont les suivants : 

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{Images/linear_score.png}
    \caption{Score obtenu pour le noyau linéaire}\label{fig : linear}
\end{figure}

Pour les données d'entraînement, le modèle a classifié correctement 69,3\% des données, contre 64\% pour les données de test. 


\subsection{Classification avec noyau polynomial}

L’utilisation d’un noyau polynomial sur les deux premières variables permet de trouver une frontière de décision non linéaire capable de séparer au mieux les deux classes. 
L'objectif est d'évaluer si l'emploi d'un noyau polynomial nous permet d'obtenir un meilleur classifieur que celui obtenu précédemment.\\
Les scores obtenus pour cette méthode sont les suivants :

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{Images/poly_score.png}
    \caption{Score obtenu pour le noyau polynomial}\label{fig : poly}
\end{figure}

Pour les données d'entraînement et de test, le modèle a classifié correctement 68\% des données. \\

\textbf{Comparaison des deux méthodes  : }\\[0.5cm]
- Nous disposons d'abord des scores obtenus en figure \ref{fig : linear} et figure \ref{fig : poly}.
On remarque que le score de test obtenu pour le noyau polynomial est supérieur à celui du noyau linéaire : $0.68 \geq 0.64$.
La différence reste toutefois relativement faible, ce qui ne permet pas de conclure à une nette supériorité du modèle polynomial.\\

- Ensuite, nous avons tracé graphiquement ces résultats à l'aide des frontières : \\
\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{Images/linear_vs_poly.png}
    \caption{Visualisation de la frontière séparant les classes 1 (en bleu) et 2 (en orange) pour les noyaux linéaire et polynomial}\label{fig : compare}
\end{figure}

La figure \ref{fig : compare} illustre les frontières de décision obtenues par les deux classifieurs appliqués au dataset \texttt{iris}.  
On remarque que la frontière associée au noyau polynomial reste proche d’une séparation linéaire. \\
En comparant les graphiques, on constate que le classifieur linéaire commet moins d’erreurs sur les données de la classe 1, tandis que le classifieur polynomial en commet moins sur les données de la classe 2.  \\
À ce stade, les performances des deux modèles semblent similaires, sans qu’un noyau ne se démarque nettement de l’autre.

\newpage

\section{SVM GUI}

Nous utilisons dans cette section le script \texttt{svm\_gui.py}  permettant de lancer une application qui évalue en temps réel l’impact du choix du noyau et du paramètre de régularisation C.
Nous avons généré manuellement une base de données très déséquilibrée (90\% vs 10\% environ). 
À l'aide d'un noyau linéaire et en faisant évoluer la valeur de C, nous obtenons la figure \ref{fig : carre}.


\begin{figure}[H]
    \centering
    \begin{subfigure}[b]{0.45\textwidth}
        \centering
        \includegraphics[width=\textwidth]{Images/C=1.png}
        \caption{C = 1}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.45\textwidth}
        \centering
        \includegraphics[width=\textwidth]{Images/C=0.3.png}
        \caption{C = 0.3}
    \end{subfigure}

    \begin{subfigure}[b]{0.45\textwidth}
        \centering
        \includegraphics[width=\textwidth]{Images/C=1bis.png}
        \caption{C = 1}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.45\textwidth}
        \centering
        \includegraphics[width=\textwidth]{Images/C=10.png}
        \caption{C = 10}
    \end{subfigure}

    \caption{Visualisation de la région de décision selon différents paramètres de régularisation C}\label{fig : carre}
\end{figure}

On s'aperçoit ici, de l’influence du paramètre de régularisation $C$ sur la frontière de décision obtenue avec un noyau linéaire.  
Lorsque $C$ est élevé (figure (a)), le modèle cherche à minimiser les erreurs de classification sur l’ensemble d’entraînement, ce qui conduit à une frontière de décision plus stricte et plus proche des données. 
À mesure que la valeur de $C$ diminue (figures (b) et (c)), la marge augmente et le modèle accepte davantage de points mal classés afin d’obtenir une séparation plus régulière.  
On observe ainsi que la diminution de $C$ rend la frontière plus « souple », permettant de mieux généraliser, mais au prix d’un plus grand nombre d’erreurs sur l’échantillon minoritaire. 
Notons que pour $C = 0.3$ (figure (d)), la frontière se décale complètement et toutes les observations se retrouvent du même côté. 
Le modèle adopte alors une solution triviale qui ne sépare plus les deux classes ce qui illustre les limites d’une trop faible valeur de $C$ dans un contexte de données déséquilibrées.  

\newpage

\section{Classification des visages}

Dans cette section, nous exploitons une base d'images extraites de « Labeled Faces in the Wild ».
L'objectif est de classifier, à l'aide d'un SVM à noyau linéaire, deux types d'images : des portraits de Tony Blair (figure \ref{fig : visages}) et de Colin Powell. 


\begin{figure}[H]
    \centering
    \includegraphics[width=0.6\textwidth]{Images/visages.png}
    \caption{Base de données de 12 portraits de Tony Blair}\label{fig : visages}
\end{figure}

\subsection{Influence du paramètre de régularisation}

Nous souhaitons observer l'influence du paramètre de régularisation $C$ sur la qualité du classifieur. 
Pour cela, nous estimons le score d'apprentissage en fonction de ce paramètre en figure \ref{fig : C}.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.6\textwidth]{Images/erreur_prediction.png}
    \caption{Score d'apprentissage en fonction du paramètres de régularisation C pour des classifieurs SVM à noyau linéaire}\label{fig : C}
\end{figure}

En faisant varier les valeurs de C entre $10^{-5}$ et $10^{5}$, on remarque qu'on atteint un score d'apprentissage maximal d'environ $0.725$ lorsque $C=10^{-1}$.
Au delà de cette valeur de C, le score reste maximal de façon constante.\\
Ce résultat est cohérent, car il est attendu qu’un SVM atteigne un score maximal pour une valeur intermédiaire de 
C. En effet, si C est trop petit il y a un risque un sous-apprentissage et s'il est trop grand, il y a un risque de sur-apprentissage.\\
Ainsi, le paramètre de régularisation optimal est $C=0.1$.\\[0.5cm]


\begin{figure}[H]    
    \centering    
    \includegraphics[width=0.8\textwidth]{Images/label_prediction.png}
    \caption{Visualisation de la prédiction, du test et de la précision}\label{fig : precision}
\end{figure}

La figure \ref{fig : precision} illustre les résultats obtenus avec le classifieur SVM linéaire optimal : 
\begin{itemize}
    \item Prédiction : matrice binaires des valeurs prédites pour les images par le classifieur entraîné.
    \item Test : matrice binaires des valeurs réelle correspondant aux images.
    \item Chance level : précision attendue si l’on prédisait toujours la classe majoritaire. Cela donne un niveau de référence minimal pour évaluer la performance du classifieur.
    \item Précision : proportion de prédictions correctes, calculée comme la fraction de valeurs correctement prédites par rapport aux valeurs réelles.
\end{itemize}

Ainsi, le classifieur linéaire atteint une performance nettement supérieure au niveau de chance, démontrant sa capacité à distinguer correctement les classes sur ce jeu de test.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.6\textwidth]{Images/prediction_visage.png}
    \caption{Prédictions faites à partir du classifieur optimal sur un échantillon d'images}\label{fig:predict}
\end{figure}

La figure \ref{fig:predict} montre un échantillon des résultats obtenues : sur 12 images, 11 ont été correctement prédites.

\subsection{Variable de nuisances}

Montrons que le score de prédiction est sensible au bruit. Pour cela, nous ajoutons des variables de bruit et
recommençons la prédiction. Le bruitage consiste à ajouter des variables de bruit (ici 300), et à les mélanger aux autres. 

Nous obtenons alors les valeurs suivantes avec et sans nuisances :

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{Images/avec_variable.png}
    \caption{Score avec variable de nuisance}\label{fig: avec}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{Images/sans_variable.png}
    \caption{Score sans variable de nuisance}\label{fig: sans}
\end{figure}

Nous constatons que le bruit endommage fortement le classifieur qui voit son score presque réduit de moitié.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.5\textwidth]{Images/coeff_visage.png}
    \caption{WTF}\label{fig : ?}
\end{figure}

\subsection{Réduction de dimensions}

A présent, nous voulons améliorer la prédiction obtenue dans la question précédente à l'aide d'une réduction de
dimension.
\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{Images/apres_reduction.png}
    \caption{}\label{fig : dim}
\end{figure}



\end{document}